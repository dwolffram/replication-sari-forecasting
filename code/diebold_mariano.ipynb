{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "from plotnine import (\n",
    "    aes,\n",
    "    element_blank,\n",
    "    element_text,\n",
    "    facet_wrap,\n",
    "    geom_text,\n",
    "    geom_tile,\n",
    "    ggplot,\n",
    "    labs,\n",
    "    scale_fill_manual,\n",
    "    scale_x_discrete,\n",
    "    scale_y_discrete,\n",
    "    theme,\n",
    "    theme_bw,\n",
    ")\n",
    "from scores.stats import statistical_tests\n",
    "\n",
    "from config import MAIN_MODELS, MODEL_ORDER, ROOT\n",
    "from src.load_data import filter_by_level, load_predictions\n",
    "from src.scoring_functions import score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_wis_raw(df):\n",
    "    # Filter rows where 'quantile' is 0.5, rename 'value' to 'med', and drop unnecessary columns\n",
    "    df_median = df[df[\"quantile\"] == 0.5].copy()\n",
    "    df_median = df_median.rename(columns={\"value\": \"med\"}).drop(\n",
    "        columns=[\"quantile\", \"pathogen\", \"retrospective\", \"truth\"], errors=\"ignore\"\n",
    "    )\n",
    "\n",
    "    # Filter rows where 'type' is 'quantile' and merge with df_median\n",
    "    df_quantile = df[df[\"type\"] == \"quantile\"].copy()\n",
    "    df = df_quantile.merge(df_median, how=\"left\")\n",
    "\n",
    "    # Compute scores and other metrics row-wise\n",
    "    df[\"wis\"] = df.apply(\n",
    "        lambda row: score(row[\"value\"], row[\"truth\"], row[\"type\"], row[\"quantile\"]),\n",
    "        axis=1,\n",
    "    )\n",
    "    df[\"spread\"] = df.apply(\n",
    "        lambda row: score(row[\"value\"], row[\"med\"], row[\"type\"], row[\"quantile\"]),\n",
    "        axis=1,\n",
    "    )\n",
    "    df[\"overprediction\"] = df.apply(\n",
    "        lambda row: row[\"wis\"] - row[\"spread\"] if row[\"med\"] > row[\"truth\"] else 0,\n",
    "        axis=1,\n",
    "    )\n",
    "    df[\"underprediction\"] = df.apply(\n",
    "        lambda row: row[\"wis\"] - row[\"spread\"] if row[\"med\"] < row[\"truth\"] else 0,\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def variant_label(name: str) -> str:\n",
    "    variant = name.partition(\"-\")[2]\n",
    "    return variant if variant else \"Coupling\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_diebold_mariano(models, variants=False):\n",
    "    df = load_predictions()\n",
    "    df = df[df.model.isin(models)].copy()\n",
    "    model_order = [m for m in MODEL_ORDER if m in models]\n",
    "    df[\"model\"] = pd.Categorical(df[\"model\"], categories=model_order, ordered=True)\n",
    "\n",
    "    df_national = filter_by_level(df, \"national\")\n",
    "    df_wis = compute_wis_raw(df_national)\n",
    "    df = (\n",
    "        df_wis.groupby([\"location\", \"age_group\", \"model\", \"date\", \"horizon\"], observed=True)[\"wis\"].mean().reset_index()\n",
    "    )\n",
    "\n",
    "    df.date = pd.to_datetime(df.date)\n",
    "\n",
    "    # keep all horizons > 0\n",
    "    df = df[df.horizon > 0].copy()\n",
    "\n",
    "    # per-model maximum available horizon\n",
    "    max_h_by_model = df.groupby(\"model\", observed=False)[\"horizon\"].max().to_dict()\n",
    "\n",
    "    df_results = pd.DataFrame()\n",
    "    for m1, m2 in combinations(model_order, 2):\n",
    "        df_pair = df[df.model.isin([m1, m2])]\n",
    "\n",
    "        # pivot to have columns per model to compute score differences\n",
    "        wide = (\n",
    "            df_pair.pivot(\n",
    "                index=[\"location\", \"age_group\", \"date\", \"horizon\"],\n",
    "                columns=\"model\",\n",
    "                values=\"wis\",\n",
    "            )\n",
    "            .rename_axis(columns=None)\n",
    "            .reset_index()\n",
    "        )\n",
    "\n",
    "        # difference m1 - m2 (will be NaN where one model lacks that horizon/date)\n",
    "        wide[\"score_diff\"] = wide[m1] - wide[m2]\n",
    "\n",
    "        # reshape to timeseries matrix: rows = dates, cols = horizons\n",
    "        df_temp = (\n",
    "            wide.pivot(index=\"date\", columns=\"horizon\", values=\"score_diff\")\n",
    "            .rename_axis(index=\"valid_date\", columns=\"horizon\")\n",
    "            .sort_index()\n",
    "        )\n",
    "\n",
    "        # only keep horizons that BOTH models support\n",
    "        allowed_horizons = [\n",
    "            int(h)\n",
    "            for h in df_temp.columns\n",
    "            if int(h) <= max_h_by_model.get(m1, -np.inf) and int(h) <= max_h_by_model.get(m2, -np.inf)\n",
    "        ]\n",
    "        if not allowed_horizons:\n",
    "            continue\n",
    "\n",
    "        df_temp = df_temp[allowed_horizons]\n",
    "\n",
    "        # drop dates where any of the kept horizons is missing\n",
    "        df_temp = df_temp.dropna()\n",
    "        if df_temp.empty:\n",
    "            continue\n",
    "\n",
    "        da = xr.DataArray(\n",
    "            data=df_temp.T.to_numpy(),\n",
    "            dims=[\"horizon\", \"valid_date\"],\n",
    "            coords={\n",
    "                \"horizon\": list(map(int, df_temp.columns)),\n",
    "                \"valid_date\": (\"valid_date\", pd.to_datetime(df_temp.index)),\n",
    "                \"h\": (\"horizon\", list(map(int, df_temp.columns))),\n",
    "            },\n",
    "            name=\"score_diff\",\n",
    "        )\n",
    "\n",
    "        results = statistical_tests.diebold_mariano(da, ts_dim=\"horizon\", h_coord=\"h\")\n",
    "        results = results[[\"horizon\", \"confidence_gt_0\"]].to_pandas().reset_index()\n",
    "        results[\"m1\"] = m1\n",
    "        results[\"m2\"] = m2\n",
    "        df_results = pd.concat([df_results, results], ignore_index=True)\n",
    "\n",
    "    df_results = df_results.rename(columns={\"confidence_gt_0\": \"pval\"})\n",
    "    df_results[\"pval_two_sided\"] = 2 * np.minimum(df_results[\"pval\"], 1 - df_results[\"pval\"])\n",
    "\n",
    "    d1 = df_results.copy()\n",
    "    d1[\"m1\"] = pd.Categorical(d1[\"m1\"], categories=model_order, ordered=True)\n",
    "    d1[\"m2\"] = pd.Categorical(d1[\"m2\"], categories=model_order[::-1], ordered=True)\n",
    "    d1[\"sig\"] = d1[\"pval_two_sided\"] < 0.05\n",
    "\n",
    "    xkw = {\"limits\": model_order, \"drop\": False}\n",
    "    ykw = {\"limits\": model_order, \"drop\": False}\n",
    "    if variants:\n",
    "        xkw[\"labels\"] = lambda xs: [variant_label(x) for x in xs]\n",
    "        ykw[\"labels\"] = lambda ys: [variant_label(y) for y in ys]\n",
    "\n",
    "    p = (\n",
    "        ggplot(d1, aes(\"m2\", \"m1\"))\n",
    "        + facet_wrap(\"horizon\", ncol=2, labeller=lambda x: \"Horizon: \" + str(x))\n",
    "        + geom_tile(aes(fill=\"sig\"), width=0.95, height=0.95, alpha=0.4, show_legend=False)\n",
    "        + geom_text(aes(label=\"pval_two_sided\"), format_string=\"{:.3f}\", size=7)\n",
    "        + scale_fill_manual(values={True: \"#228B22\", False: \"gray\"}, na_value=\"white\")\n",
    "        + scale_x_discrete(**xkw)\n",
    "        + scale_y_discrete(**ykw)\n",
    "        + theme_bw()\n",
    "        + theme(\n",
    "            panel_grid=element_blank(),\n",
    "            plot_title=element_text(size=11),\n",
    "            strip_text=element_text(size=9),\n",
    "            legend_title=element_text(size=9),\n",
    "            legend_text=element_text(size=8),\n",
    "            axis_title=element_text(size=10),\n",
    "            axis_text_x=element_text(size=8, rotation=90, ha=\"center\", ma=\"right\"),\n",
    "            axis_text_y=element_text(size=8),\n",
    "        )\n",
    "        + labs(x=\"\", y=\"\", title=models[0] if variants else \"\")\n",
    "    )\n",
    "\n",
    "    return p\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = plot_diebold_mariano(MAIN_MODELS, False)\n",
    "p.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "p.save(ROOT / \"figures\" / \"dm_test.pdf\", width=160, height=140, units=\"mm\", dpi=600, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "hhh4_variants = [\"hhh4\", \"hhh4-Oracle\", \"hhh4-Discard\", \"hhh4-Naive\"]\n",
    "\n",
    "lightgbm_variants = [\n",
    "    \"LightGBM\",\n",
    "    \"LightGBM-Oracle\",\n",
    "    \"LightGBM-Discard\",\n",
    "    \"LightGBM-Naive\",\n",
    "]\n",
    "\n",
    "tsmixer_variants = [\n",
    "    \"TSMixer\",\n",
    "    \"TSMixer-Oracle\",\n",
    "    \"TSMixer-Discard\",\n",
    "    \"TSMixer-Naive\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = plot_diebold_mariano(hhh4_variants, True)\n",
    "p.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "p.save(\n",
    "    ROOT / \"figures\" / \"dm_test_hhh4.pdf\",\n",
    "    width=95,\n",
    "    height=80,\n",
    "    units=\"mm\",\n",
    "    dpi=600,\n",
    "    verbose=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = plot_diebold_mariano(lightgbm_variants, True)\n",
    "p.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "p.save(\n",
    "    ROOT / \"figures\" / \"dm_test_lightgbm.pdf\",\n",
    "    width=95,\n",
    "    height=80,\n",
    "    units=\"mm\",\n",
    "    dpi=600,\n",
    "    verbose=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = plot_diebold_mariano(tsmixer_variants, True)\n",
    "p.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "p.save(\n",
    "    ROOT / \"figures\" / \"dm_test_tsmixer.pdf\",\n",
    "    width=95,\n",
    "    height=80,\n",
    "    units=\"mm\",\n",
    "    dpi=600,\n",
    "    verbose=False,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "replication-sari",
   "language": "python",
   "name": "replication-sari"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
