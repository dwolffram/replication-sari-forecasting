{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# TSMixer: Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.silence import silence\n",
    "\n",
    "silence()\n",
    "\n",
    "import ast\n",
    "import os\n",
    "from itertools import product\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from darts.models import TSMixerModel\n",
    "from darts.utils.likelihood_models import NegativeBinomialLikelihood\n",
    "from tqdm import tqdm\n",
    "\n",
    "from config import METRIC, METRIC_KWARGS, ROOT\n",
    "from src.tuning import compute_validation_score, exclude_covid_weights, train_validation_split\n",
    "from src.realtime_utils import load_realtime_training_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"tsmixer\"\n",
    "OUT_CSV = ROOT / \"results\" / \"tuning\" / \"gridsearch_tsmixer.csv\"\n",
    "RANDOM_SEEDS = [1, 2, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_SAMPLES = 1000\n",
    "HORIZON = 4\n",
    "\n",
    "ENCODERS = {\"datetime_attribute\": {\"future\": [\"month\", \"weekofyear\"]}}\n",
    "\n",
    "SHARED_ARGS = dict(\n",
    "    output_chunk_length=HORIZON,\n",
    "    likelihood=NegativeBinomialLikelihood(),\n",
    "    pl_trainer_kwargs={\n",
    "        \"enable_progress_bar\": False,\n",
    "        \"enable_model_summary\": False,\n",
    "        \"accelerator\": \"cpu\",\n",
    "        \"logger\": False,\n",
    "        # \"callbacks\" : [RichProgressBar(leave=True)],\n",
    "    },\n",
    ")\n",
    "\n",
    "OPTIMIZER_DICT = {\"Adam\": torch.optim.Adam, \"AdamW\": torch.optim.AdamW, \"SGD\": torch.optim.SGD}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_configuration = {\n",
    "    \"name\": f\"sari-{NAME}\",\n",
    "    \"method\": \"grid\",\n",
    "    \"metric\": {\"goal\": \"minimize\", \"name\": \"WIS\"},\n",
    "    \"parameters\": {\n",
    "        \"use_static_covariates\": {\"values\": [False]},\n",
    "        \"use_covariates\": {\"values\": [True, False]},\n",
    "        \"use_encoders\": {\"values\": [True]},\n",
    "        \"sample_weight\": {\"values\": [\"linear\", \"no-covid\"]},\n",
    "        \"input_chunk_length\": {\"values\": [8]},\n",
    "        \"hidden_size\": {\"values\": [32, 64]},\n",
    "        \"ff_size\": {\"values\": [32, 64]},\n",
    "        \"num_blocks\": {\"values\": [4, 6]},\n",
    "        \"dropout\": {\"values\": [0.2]},  # 0.05, 0.1, 0.2, 0.3, 0.5\n",
    "        \"norm_type\": {\"values\": [\"TimeBatchNorm2d\"]},  # 'LayerNorm',\n",
    "        \"batch_size\": {\"values\": [32]},\n",
    "        \"n_epochs\": {\"values\": [500, 1000]},\n",
    "        \"normalize_before\": {\"values\": [False]},\n",
    "        \"activation\": {\"values\": [\"ReLU\"]},  # \"ReLU\", \"GELU\", \"LeakyReLU\", \"ELU\"\n",
    "        \"optimizer\": {\"values\": [\"AdamW\"]},  # SGD, \"Adam\",\n",
    "        \"optimizer_kwargs\": {\n",
    "            \"parameters\": {\"lr\": {\"values\": [0.0005, 0.001, 0.005]}, \"weight_decay\": {\"values\": [0, 0.001, 0.0001]}}\n",
    "        },\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def space_from_sweep(sweep_cfg: dict) -> dict:\n",
    "    space = {}\n",
    "    for k, v in sweep_cfg[\"parameters\"].items():\n",
    "        if k == \"optimizer_kwargs\":  # special case: flatten\n",
    "            sub = v[\"parameters\"]\n",
    "            space[\"optimizer_kwargs.lr\"] = list(sub[\"lr\"][\"values\"])\n",
    "            space[\"optimizer_kwargs.weight_decay\"] = list(sub[\"weight_decay\"][\"values\"])\n",
    "        else:\n",
    "            space[k] = list(v[\"values\"])\n",
    "    return space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iter_configs(space: dict):\n",
    "    keys = list(space.keys())\n",
    "    for vals in product(*(space[k] for k in keys)):\n",
    "        yield dict(zip(keys, vals))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets, covariates = load_realtime_training_data()\n",
    "\n",
    "targets_train, targets_validation = train_validation_split(targets, 2022)\n",
    "\n",
    "targets_validation[\"icosari-sari-DE\"].plot(label=\"validation\")\n",
    "targets_train[\"icosari-sari-DE\"].plot(label=\"train\")\n",
    "\n",
    "custom_weights = exclude_covid_weights(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_config(cfg: dict) -> dict:\n",
    "    optimizer = OPTIMIZER_DICT[cfg[\"optimizer\"]]\n",
    "    use_covariates = cfg[\"use_covariates\"]\n",
    "    sample_weight = cfg[\"sample_weight\"]\n",
    "\n",
    "    scores = {}\n",
    "    for seed in RANDOM_SEEDS:\n",
    "        model = TSMixerModel(\n",
    "            input_chunk_length=cfg[\"input_chunk_length\"],\n",
    "            hidden_size=cfg[\"hidden_size\"],\n",
    "            ff_size=cfg[\"ff_size\"],\n",
    "            num_blocks=cfg[\"num_blocks\"],\n",
    "            dropout=cfg[\"dropout\"],\n",
    "            norm_type=cfg[\"norm_type\"],\n",
    "            batch_size=cfg[\"batch_size\"],\n",
    "            n_epochs=cfg[\"n_epochs\"],\n",
    "            normalize_before=cfg[\"normalize_before\"],\n",
    "            activation=cfg[\"activation\"],\n",
    "            optimizer_cls=optimizer,\n",
    "            optimizer_kwargs={\n",
    "                \"lr\": cfg[\"optimizer_kwargs.lr\"],\n",
    "                \"weight_decay\": cfg[\"optimizer_kwargs.weight_decay\"],\n",
    "            },\n",
    "            use_static_covariates=cfg[\"use_static_covariates\"],\n",
    "            add_encoders=ENCODERS if cfg[\"use_encoders\"] else None,\n",
    "            **SHARED_ARGS,\n",
    "            random_state=seed,\n",
    "        )\n",
    "\n",
    "        score = compute_validation_score(\n",
    "            model,\n",
    "            targets_train,\n",
    "            targets_validation,\n",
    "            covariates if use_covariates else None,\n",
    "            HORIZON,\n",
    "            NUM_SAMPLES,\n",
    "            METRIC,\n",
    "            METRIC_KWARGS,\n",
    "            sample_weight=custom_weights if sample_weight == \"no-covid\" else sample_weight,\n",
    "        )\n",
    "        scores[f\"WIS_{seed}\"] = score\n",
    "\n",
    "    per_seed = list(scores.values())\n",
    "    scores[\"WIS\"] = np.mean(per_seed)\n",
    "    scores[\"WIS_std\"] = np.std(per_seed)\n",
    "\n",
    "    return {\n",
    "        **scores,\n",
    "        **{f\"cfg.{k}\": v for k, v in cfg.items()},\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_gridsearch(resume=False):\n",
    "    space = space_from_sweep(sweep_configuration)\n",
    "    configs = list(iter_configs(space))\n",
    "\n",
    "    param_cols = list(space.keys())\n",
    "    score_cols = [\"WIS_1\", \"WIS_2\", \"WIS_3\", \"WIS\", \"WIS_std\"]\n",
    "    header = param_cols + score_cols + [\"error_flag\", \"error_msg\"]\n",
    "\n",
    "    if resume and os.path.exists(OUT_CSV):\n",
    "        gs = pd.read_csv(OUT_CSV)\n",
    "\n",
    "        # convert string representations into dicts and tuples\n",
    "        gs[\"lags_past_covariates\"] = gs[\"lags_past_covariates\"].apply(\n",
    "            lambda x: ast.literal_eval(x) if isinstance(x, str) else x\n",
    "        )\n",
    "        gs[\"lags_future_covariates\"] = gs[\"lags_future_covariates\"].apply(\n",
    "            lambda x: ast.literal_eval(x) if isinstance(x, str) else x\n",
    "        )\n",
    "\n",
    "        gs = gs.drop(columns=[\"WIS\", \"error_flag\", \"error_msg\"]).to_dict(\"records\")\n",
    "        configs = [c for c in configs if c not in gs]\n",
    "\n",
    "    if not os.path.exists(OUT_CSV):\n",
    "        pd.DataFrame(columns=header).to_csv(OUT_CSV, index=False)\n",
    "\n",
    "    total = len(configs)\n",
    "    pbar = tqdm(configs, total=total, desc=\"Grid search\", unit=\"trial\")\n",
    "    for cfg in pbar:\n",
    "        row = {k: cfg.get(k) for k in param_cols}\n",
    "        try:\n",
    "            res = eval_config(cfg)\n",
    "            for sc in score_cols:\n",
    "                row[sc] = res.get(sc, np.nan)\n",
    "            row.update({\"error_flag\": False, \"error_msg\": \"\"})\n",
    "            wis = row[\"WIS\"]\n",
    "        except Exception as e:\n",
    "            for sc in score_cols:\n",
    "                row[sc] = np.nan\n",
    "            row.update({\"error_flag\": True, \"error_msg\": str(e)})\n",
    "            wis = np.nan\n",
    "\n",
    "        pd.DataFrame([row], columns=header).to_csv(OUT_CSV, mode=\"a\", header=False, index=False)\n",
    "\n",
    "        pbar.set_postfix(\n",
    "            {\n",
    "                \"WIS\": f\"{wis:.4f}\" if isinstance(wis, (float, np.floating)) and not np.isnan(wis) else \"nan\",\n",
    "            }\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_gridsearch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "replication-sari",
   "language": "python",
   "name": "replication-sari"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
